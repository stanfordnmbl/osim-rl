---
title: Welcome
permalink: /docs/home/
redirect_from: /docs/index.html
---

`osim-rl` package allows you to synthesize physiologically accurate movement by combining biomechanical expertise embeded in [OpenSim](http://opensim.stanford.edu/) simulation software with state-of-the-art control strategies using Deep Reinforcement Learning.

![HUMAN environment](https://s3.amazonaws.com/osim-rl/videos/running.gif)

Our objectives are to:
* use Reinforcement Learning (RL) to solve problems in healthcare,
* promote open-source tools in RL research ([the physics simulator](http://opensim.stanford.edu), [the RL environment](https://github.com/stanfordnmbl/osim-rl), and the [competition platform](http://crowdai.org/) on which we run challenges are all open-source),
* encourage RL research in computationally complex environments, with stochasticity and highly-dimensional action spaces, relevant to real-life applications,
* bridge biomechanics, neuroscience, and computer science communities.

<!--
## What can I find here?

Human movement results from the intricate coordination of muscles, tendons, joints, and other physiological elements. While children learn to walk, run, climb, and jump in their first years of life and most of us can navigate complex environments--like a crowded street or moving subway--without considerable active attention, developing controllers that can efficiently and robustly synthesize realistic human motions in a variety of environments remains a grand challenge for biomechanists, neuroscientists, and computer scientists. Current controllers are confined to a small set of pre-specified movements or driven by torques, rather than the complex muscle actuators found in humans.
-->
